MIT 6.00.2x - Introduction to Computational Thinking and Data Science

These are my implementation of the Problem Sets for the "MIT 6.00.2x - "Introduction to Computational Thinking and Data Science" course.

This course started on 17th October 2018 and ended on 20th December 2018.

This repository has the following files:  
• 6.00.2x-pset1.py - Problem Set 2  
• 6.00.2x-pset2.py - Problem Set 3 "A hangman game"  
• 6.00.2x-pset3.py - Problem Set 4 "A wordgame"  
• ps1_cow_data.txt - A file provided containing data to use on Problem Set 1   
• ps1_partition.py - A file provided containing a few helper functions to use on Problem Set 1  
• ps2_visualize.py - A file provided containing a few helper functions to use on Problem Set 2  
• ps2_visualize.py - A file provided containing a few helper functions to use on Problem Set 2  
• ps3b_precompiled_36.pyc - A file provided containing a few helper functions to use on Problem Set 2  
Other Problem Sets were not included because they were just questions with multiple choice answers.  

The topics covered by this course were:  
  Lecture 1 – Optimization and Knapsack Problem:  
  • Computational models  
  • Intro to optimization  
  • 0/1 Knapsack Problem  
  • Greedy solutions  
  Lecture 2 – Decision Trees and Dynamic Programming:  
  • Decision tree solution to knapsack  
  • Dynamic programming and knapsack  
  • Divide and conquer  
  Lecture 3 – Graphs:  
  • Graph problems  
  • Shortest path  
  • Depth first search  
  • Breadth first search  
  Lecture 4 – Plotting:  
  • Visualizing Results  
  • Overlapping Displays  
  • Adding More Documentation  
  • Changing Data Display  
  • An Example  
  Lecture 5 – Stochastic Thinking:  
  • Rolling a Die  
  • Random walks  
  Lecture 6 – Random Walks:  
  • Drunk walk  
  • Biased random walks  
  • Treacherous fields  
  Lecture 7 – Inferential Statistics:  
  • Probabilities  
  • Confidence intervals  
  Lecture 8 – Monte Carlo Simulations:  
  Lecture 9 – Monte Carlo Simulations:  
  • Sampling  
  • Standard error  
  Lecture 10 – Experimental Data:  
  • Errors in Experimental Observations  
  • Curve Fitting  
  Lecture 11 – Experimental Data:  
  • Goodness of Fit  
  • Using a Model for Predictions  
  Lecture 12 – Machine Learning:  
  • Feature Vectors  
  • Distance Metrics  
  • Clustering  
  Lecture 13 – Statistical Fallacies  
  • Misusing Statistics  
  • Garbage In Garbage Out  
  • Data Enhancement  
